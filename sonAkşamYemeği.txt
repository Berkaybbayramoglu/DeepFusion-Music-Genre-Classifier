import pickle
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import os
import sys
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import matplotlib.pyplot as plt
import random
import torch.nn.functional as F
import torchvision.models as models
from collections import Counter
from tqdm import tqdm
import csv

# --- Seed Setting ---
def set_seed(seed):
    """Sets random seeds for reproducibility across libraries (Python, NumPy, PyTorch, cuDNN)."""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False
    print(f"All random seeds set to {seed}.")

SEED = 42
set_seed(SEED)

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {DEVICE}")

# Constants
FEATURES_FILE_PATH = r"/kaggle/input/morefeatures2improveddataset/gtzan_multi_modal_features_hps2.pkl"
NUM_CLASSES = 10
BATCH_SIZE = 64
LEARNING_RATE = 0.0001 # Lower LR for ResNet-50 fine-tuning
NUM_EPOCHS = 250
PATIENCE = 25 # Early stopping patience
VALIDATION_SPLIT_RATIO = 0.2

RESULTS_CSV_PATH = "./training_results_single_split.csv"
MODEL_SAVE_DIR = "./trained_models_pytorch_single_split"

# --- 1. Dataset Class ---
class MultiModalDataset(Dataset):
    """
    Custom PyTorch Dataset for multi-modal audio features.
    Converts preprocessed NumPy arrays to PyTorch tensors.
    """
    def __init__(self, mel_orig_data, mel_harm_data, mel_perc_data, mfcc_data, chroma_data, tempogram_data, labels):
        self.mel_orig_data = torch.tensor(mel_orig_data, dtype=torch.float32)
        self.mel_harm_data = torch.tensor(mel_harm_data, dtype=torch.float32)
        self.mel_perc_data = torch.tensor(mel_perc_data, dtype=torch.float32)
        
        self.mfcc_data = torch.tensor(mfcc_data, dtype=torch.float32)
        self.chroma_data = torch.tensor(chroma_data, dtype=torch.float32)
        self.tempogram_data = torch.tensor(tempogram_data, dtype=torch.float32)
        
        self.labels = torch.tensor(labels, dtype=torch.long)

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        return {
            'mel_orig': self.mel_orig_data[idx],
            'mel_harm': self.mel_harm_data[idx],
            'mel_perc': self.mel_perc_data[idx],
            'mfcc': self.mfcc_data[idx],
            'chroma': self.chroma_data[idx],
            'tempogram': self.tempogram_data[idx],
        }, self.labels[idx]

# --- 2. Feature Loading Function ---
def load_features(file_path):
    """Loads pre-extracted audio features from a pickle file."""
    if not os.path.exists(file_path):
        print(f"ERROR: Features file not found: '{file_path}'")
        raise FileNotFoundError(f"Features file not found: '{file_path}'")
    
    print(f"Loading features from: '{file_path}'...")
    with open(file_path, 'rb') as f:
        all_clips_raw_data = pickle.load(f)
    print(f"Total {len(all_clips_raw_data)} clips loaded.")
    
    all_features = [item['features'] for item in all_clips_raw_data]
    all_labels = [item['label'] for item in all_clips_raw_data]
    original_files = [item['original_file'] for item in all_clips_raw_data]
    
    return all_features, all_labels, original_files

# --- 3. Data Preparation and DataLoader Creation Function ---
def preprocess_all_features(all_features, all_labels):
    """Extracts, organizes, and prepares features, adding a channel dimension for CNN inputs."""
    mel_orig_specs = np.array([f['mel_spec_orig'] for f in all_features])
    mel_harm_specs = np.array([f['mel_spec_harm'] for f in all_features])
    mel_perc_specs = np.array([f['mel_spec_perc'] for f in all_features])
    mfccs = np.array([f['mfcc'] for f in all_features])
    chromas = np.array([f['chroma'] for f in all_features])
    tempograms = np.array([f['tempogram'] for f in all_features])
    
    labels = np.array(all_labels)

    # Add channel dimension (1) expected by ResNet for grayscale images
    if mel_orig_specs.ndim == 3:
        mel_orig_specs = np.expand_dims(mel_orig_specs, axis=1)
    if mel_harm_specs.ndim == 3:
        mel_harm_specs = np.expand_dims(mel_harm_specs, axis=1)
    if mel_perc_specs.ndim == 3:
        mel_perc_specs = np.expand_dims(mel_perc_specs, axis=1)

    print(f"Mel-spectrogram Original shape (channel added): {mel_orig_specs.shape}")
    print(f"Mel-spectrogram Harmonic shape (channel added): {mel_harm_specs.shape}")
    print(f"Mel-spectrogram Percussive shape (channel added): {mel_perc_specs.shape}")
    print(f"MFCC shape: {mfccs.shape}")
    print(f"Chroma shape: {chromas.shape}")
    print(f"Tempogram shape: {tempograms.shape}")
    print(f"Labels shape: {labels.shape}")

    print("\nGeneral data preparation completed.")
    return (mel_orig_specs, mel_harm_specs, mel_perc_specs, 
            mfccs, chromas, tempograms, labels)

def create_data_loaders(
    all_mel_orig, all_mel_harm, all_mel_perc, 
    all_mfcc, all_chroma, all_tempogram, all_labels, 
    validation_split_ratio, random_seed
):
    """
    Splits data into training/validation, applies StandardScaler to auxiliary features,
    and creates DataLoaders. Stratified split preserves class distribution.
    """
    num_samples = len(all_labels)
    indices = np.arange(num_samples)

    # Stratified split to maintain class balance in train/val sets
    train_indices, val_indices, _, y_val_for_stratify = train_test_split(
        indices, all_labels, test_size=validation_split_ratio, stratify=all_labels, random_state=random_seed
    )

    print(f"Number of training clips: {len(train_indices)}, Number of validation clips: {len(val_indices)}")

    # Separate features based on indices
    X_train_mel_orig = all_mel_orig[train_indices]
    X_train_mel_harm = all_mel_harm[train_indices]
    X_train_mel_perc = all_mel_perc[train_indices]
    X_train_mfcc = all_mfcc[train_indices]
    X_train_chroma = all_chroma[train_indices]
    X_train_tempogram = all_tempogram[train_indices]
    y_train = all_labels[train_indices]

    X_val_mel_orig = all_mel_orig[val_indices]
    X_val_mel_harm = all_mel_harm[val_indices]
    X_val_mel_perc = all_mel_perc[val_indices]
    X_val_mfcc = all_mfcc[val_indices]
    X_val_chroma = all_chroma[val_indices]
    X_val_tempogram = all_tempogram[val_indices]
    y_val = all_labels[val_indices]

    # --- Feature Scaling ---
    scalers = {}
    scaled_train_features = {}
    scaled_val_features = {}

    features_to_scale = {
        'mfcc': (X_train_mfcc, X_val_mfcc),
        'chroma': (X_train_chroma, X_val_chroma),
        'tempogram': (X_train_tempogram, X_val_tempogram),
    }

    # Apply StandardScaler: fit on training data, transform both train and val
    for name, (train_data, val_data) in features_to_scale.items():
        scaler = StandardScaler()
        scaled_train_features[name] = scaler.fit_transform(train_data)
        scaled_val_features[name] = scaler.transform(val_data)
        scalers[name] = scaler 

    train_dataset = MultiModalDataset(
        X_train_mel_orig, X_train_mel_harm, X_train_mel_perc,
        scaled_train_features['mfcc'], scaled_train_features['chroma'], scaled_train_features['tempogram'],
        y_train
    )
    val_dataset = MultiModalDataset(
        X_val_mel_orig, X_val_mel_harm, X_val_mel_perc,
        scaled_val_features['mfcc'], scaled_val_features['chroma'], scaled_val_features['tempogram'],
        y_val
    )

    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, drop_last=True)
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, drop_last=True)

    return train_loader, val_loader, y_train # y_train returned for class weight calculation

# --- 4. Model Architecture ---
class MelCNN(nn.Module):
    """
    CNN branch for mel-spectrograms using a pre-trained ResNet-50.
    Modifies the first conv layer for single-channel input and adds a custom FC layer.
    """
    def __init__(self, output_dim=256, pretrained=True):
        super(MelCNN, self).__init__()
        resnet = models.resnet50(pretrained=pretrained)
        resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False) # Adjust for 1-channel input
        self.features = nn.Sequential(*list(resnet.children())[:-1]) # Remove original FC layer
        self.fc = nn.Sequential(
            nn.Linear(2048, output_dim),
            nn.ReLU(),
            nn.Dropout(0.5)
        )

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1) # Flatten
        x = self.fc(x)
        return x

class AuxiliaryFeatureMLP(nn.Module):
    """MLP branch for auxiliary features (MFCC, Chroma, Tempogram) with BatchNorm and Dropout."""
    def __init__(self, input_size, hidden_size1, hidden_size2, dropout_rate=0.5):
        super(AuxiliaryFeatureMLP, self).__init__()
        self.network = nn.Sequential(
            nn.Linear(input_size, hidden_size1),
            nn.BatchNorm1d(hidden_size1),
            nn.ReLU(),
            nn.Dropout(dropout_rate), 
            nn.Linear(hidden_size1, hidden_size2),
            nn.BatchNorm1d(hidden_size2),
            nn.ReLU(),
            nn.Dropout(dropout_rate)
        )

    def forward(self, x):
        return self.network(x)

class MultiModalNet(nn.Module):
    """
    Main multi-modal network combining Mel-CNN branches and Auxiliary MLPs.
    Uses an attention mechanism to weight the contribution of each modality
    before final fusion and classification.
    """
    def __init__(self, num_classes):
        super(MultiModalNet, self).__init__()
        self.mel_orig_branch = MelCNN(pretrained=True, output_dim=256)
        self.mel_harm_branch = MelCNN(pretrained=True, output_dim=256)
        self.mel_perc_branch = MelCNN(pretrained=True, output_dim=256)
        
        self.mfcc_branch = AuxiliaryFeatureMLP(input_size=20, hidden_size1=128, hidden_size2=32, dropout_rate=0.5)
        self.chroma_branch = AuxiliaryFeatureMLP(input_size=12, hidden_size1=64, hidden_size2=16, dropout_rate=0.5)
        self.tempogram_branch = AuxiliaryFeatureMLP(input_size=384, hidden_size1=128, hidden_size2=32, dropout_rate=0.5)
        
        self.mel_output_dim = 256
        self.mfcc_output_dim = 32
        self.chroma_output_dim = 16
        self.tempogram_output_dim = 32

        self.num_modalities = 3 + 3

        self.total_feature_dim = (self.mel_output_dim * 3) + \
                                 self.mfcc_output_dim + \
                                 self.chroma_output_dim + \
                                 self.tempogram_output_dim
                                 
        self.attention_weights_layer = nn.Linear(self.total_feature_dim, self.num_modalities)

        self.fusion_fc = nn.Sequential(
            nn.Linear(self.total_feature_dim, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(),
            nn.Dropout(0.6), # Increased dropout
            nn.Linear(512, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(),
            nn.Dropout(0.6) # Increased dropout
        )
        self.classifier = nn.Linear(256, num_classes)

    def forward(self, x):
        mel_orig_output = self.mel_orig_branch(x['mel_orig'])
        mel_harm_output = self.mel_harm_branch(x['mel_harm'])
        mel_perc_output = self.mel_perc_branch(x['mel_perc'])
        
        mfcc_output = self.mfcc_branch(x['mfcc'])
        chroma_output = self.chroma_branch(x['chroma'])
        tempogram_output = self.tempogram_branch(x['tempogram'])

        combined_features_raw = torch.cat(
            (mel_orig_output, mel_harm_output, mel_perc_output,
             mfcc_output, chroma_output, tempogram_output), dim=1
        )
        
        attention_logits = self.attention_weights_layer(combined_features_raw)
        attention_weights = F.softmax(attention_logits, dim=1) # Softmax to get probabilities for each modality

        # Apply attention weights to each modality's output
        weighted_mel_orig_output = mel_orig_output * attention_weights[:, 0].unsqueeze(1)
        weighted_mel_harm_output = mel_harm_output * attention_weights[:, 1].unsqueeze(1)
        weighted_mel_perc_output = mel_perc_output * attention_weights[:, 2].unsqueeze(1)
        weighted_mfcc_output = mfcc_output * attention_weights[:, 3].unsqueeze(1)
        weighted_chroma_output = chroma_output * attention_weights[:, 4].unsqueeze(1)
        weighted_tempogram_output = tempogram_output * attention_weights[:, 5].unsqueeze(1)

        combined_features_weighted = torch.cat(
            (weighted_mel_orig_output, weighted_mel_harm_output, weighted_mel_perc_output,
             weighted_mfcc_output, weighted_chroma_output, weighted_tempogram_output), dim=1
        )

        fusion_output = self.fusion_fc(combined_features_weighted)
        output = self.classifier(fusion_output)
        return output

# --- 5. Training and Evaluation Functions ---

def log_results_to_csv(file_path, data, mode='a', header=True):
    """Logs training results (epoch, loss, accuracy) to a CSV file."""
    if isinstance(data, dict):
        data = [data]
    file_exists = os.path.exists(file_path)
    with open(file_path, mode, newline='') as csvfile:
        fieldnames = list(data[0].keys())
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        if header and (not file_exists or mode == 'w'):
            writer.writeheader()
        writer.writerows(data)
    print(f"Results saved to '{file_path}' file.")

def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, model_save_dir):
    """
    Trains the model with validation, early stopping, and model checkpointing.
    Saves the model with the lowest validation loss.
    """
    history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}
    best_val_loss = float('inf')
    epochs_no_improve = 0

    if not os.path.exists(model_save_dir):
        os.makedirs(model_save_dir)
        print(f"Model save directory created: {model_save_dir}")

    # Clear previous results CSV
    if os.path.exists(RESULTS_CSV_PATH):
        os.remove(RESULTS_CSV_PATH)
        print(f"Old results file '{RESULTS_CSV_PATH}' deleted.")

    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0
        correct_train = 0
        total_train = 0
        
        train_loader_tqdm = tqdm(train_loader, desc=f"Epoch {epoch+1}/{num_epochs} Training")
        for batch_idx, (inputs, labels) in enumerate(train_loader_tqdm):
            inputs = {k: v.to(DEVICE) for k, v in inputs.items()}
            labels = labels.to(DEVICE)

            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item() * labels.size(0)
            _, predicted = torch.max(outputs.data, 1)
            total_train += labels.size(0)
            correct_train += (predicted == labels).sum().item()
            
            train_loader_tqdm.set_postfix(loss=loss.item())

        epoch_train_loss = running_loss / total_train
        epoch_train_acc = correct_train / total_train
        
        model.eval()
        val_loss = 0.0
        correct_val = 0
        total_val = 0
        with torch.no_grad():
            val_loader_tqdm = tqdm(val_loader, desc=f"Epoch {epoch+1}/{num_epochs} Validation")
            for inputs, labels in val_loader_tqdm:
                inputs = {k: v.to(DEVICE) for k, v in inputs.items()}
                labels = labels.to(DEVICE)
                outputs = model(inputs)
                loss = criterion(outputs, labels)

                val_loss += loss.item() * labels.size(0)
                _, predicted = torch.max(outputs.data, 1)
                total_val += labels.size(0)
                correct_val += (predicted == labels).sum().item()
                
                val_loader_tqdm.set_postfix(loss=loss.item())

        epoch_val_loss = val_loss / total_val
        epoch_val_acc = correct_val / total_val

        history['train_loss'].append(epoch_train_loss)
        history['val_loss'].append(epoch_val_loss)
        history['train_acc'].append(epoch_train_acc)
        history['val_acc'].append(epoch_val_acc)

        print(f"Epoch {epoch+1}/{num_epochs} - Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_acc:.4f}, Val Loss: {epoch_val_loss:.4f}, Val Acc: {epoch_val_acc:.4f}")

        scheduler.step(epoch_val_loss) # Adjust learning rate based on validation loss

        log_data = {
            'epoch': epoch + 1,
            'train_loss': f"{epoch_train_loss:.4f}",
            'train_accuracy': f"{epoch_train_acc:.4f}",
            'val_loss': f"{epoch_val_loss:.4f}",
            'val_accuracy': f"{epoch_val_acc:.4f}",
            'learning_rate': f"{optimizer.param_groups[0]['lr']:.6f}"
        }
        log_results_to_csv(RESULTS_CSV_PATH, log_data, mode='a', header=(epoch == 0)) 

        if epoch_val_loss < best_val_loss:
            best_val_loss = epoch_val_loss
            epochs_no_improve = 0
            torch.save(model.state_dict(), os.path.join(model_save_dir, 'best_multi_modal_gtzan_model.pth'))
            print(f"Best model saved: Epoch {epoch+1}, Val Loss: {best_val_loss:.4f}")
        else:
            epochs_no_improve += 1
            if epochs_no_improve == PATIENCE:
                print(f"Early Stopping: Validation loss did not improve for {PATIENCE} epochs. Training stopped.")
                break
    return history

def evaluate_model(model, data_loader, criterion):
    """Evaluates the model on a given DataLoader, returns average loss and accuracy."""
    model.eval()
    total_loss = 0.0
    correct_predictions = 0
    total_samples = 0
    with torch.no_grad():
        for inputs, labels in tqdm(data_loader, desc="Evaluating"):
            inputs = {k: v.to(DEVICE) for k, v in inputs.items()}
            labels = labels.to(DEVICE)
            outputs = model(inputs)
            loss = criterion(outputs, labels)

            total_loss += loss.item() * labels.size(0)
            _, predicted = torch.max(outputs.data, 1)
            total_samples += labels.size(0)
            correct_predictions += (predicted == labels).sum().item()

    avg_loss = total_loss / total_samples
    accuracy = correct_predictions / total_samples
    return avg_loss, accuracy

def plot_training_history(history, save_path):
    """Plots and saves the training and validation loss/accuracy curves."""
    plt.figure(figsize=(12, 5))

    plt.subplot(1, 2, 1)
    plt.plot(history['train_loss'], label='Training Loss')
    plt.plot(history['val_loss'], label='Validation Loss')
    plt.title('Training and Validation Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True)

    plt.subplot(1, 2, 2)
    plt.plot(history['train_acc'], label='Training Accuracy')
    plt.plot(history['val_acc'], label='Validation Accuracy')
    plt.title('Training and Validation Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.grid(True)

    plt.tight_layout()
    plt.savefig(save_path)
    plt.show()
    print(f"Training history plot saved to '{save_path}'.")


if __name__ == "__main__":
    set_seed(SEED) # Ensure reproducibility if script is run directly

    all_features, all_labels, original_files = load_features(FEATURES_FILE_PATH)
    
    (mel_orig_specs, mel_harm_specs, mel_perc_specs, 
     mfccs, chromas, tempograms, labels) = \
        preprocess_all_features(all_features, all_labels)

    train_loader, val_loader, y_train_full_labels = create_data_loaders(
        mel_orig_specs, mel_harm_specs, mel_perc_specs, 
        mfccs, chromas, tempograms, labels, 
        VALIDATION_SPLIT_RATIO, SEED
    )

    # Calculate class weights for CrossEntropyLoss to handle class imbalance
    class_counts = Counter(y_train_full_labels.tolist())
    total_samples = sum(class_counts.values())
    class_weights = torch.tensor([total_samples / (NUM_CLASSES * class_counts[i]) 
                                  for i in range(NUM_CLASSES)], dtype=torch.float32).to(DEVICE)
    print(f"Calculated Class Weights (Full Training Set): {class_weights}")

    model = MultiModalNet(NUM_CLASSES).to(DEVICE)
    criterion = nn.CrossEntropyLoss(weight=class_weights) # Apply class weights
    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4) # Adam optimizer with L2 regularization
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.2, patience=PATIENCE-5, verbose=True) # Reduce LR on plateau

    print(f"\nModel Architecture:")
    # print(model) # Uncomment to view full model architecture

    history = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, NUM_EPOCHS, MODEL_SAVE_DIR)

    print(f"\nTraining completed. The best model is saved to '{MODEL_SAVE_DIR}' directory.")
    
    # Load and evaluate the best saved model on the validation set
    best_model_path = os.path.join(MODEL_SAVE_DIR, 'best_multi_modal_gtzan_model.pth')
    if os.path.exists(best_model_path):
        model.load_state_dict(torch.load(best_model_path))
        print(f"Best model loaded from '{best_model_path}'. Performing final evaluation on the validation set...")
        val_loss, val_accuracy = evaluate_model(model, val_loader, criterion)
        print(f"Final Validation Loss: {val_loss:.4f}")
        print(f"Final Validation Accuracy: {val_accuracy:.4f}")
    else:
        print(f"WARNING: Best model file '{best_model_path}' not found. Using the model state from the last epoch.")
        val_loss = history['val_loss'][-1] if history['val_loss'] else float('nan')
        val_accuracy = history['val_acc'][-1] if history['val_acc'] else float('nan')
        print(f"Last Epoch Validation Loss: {val_loss:.4f}")
        print(f"Last Epoch Validation Accuracy: {val_accuracy:.4f}")

    plot_training_history(history, save_path=os.path.join(MODEL_SAVE_DIR, f"training_history_single_split.png"))